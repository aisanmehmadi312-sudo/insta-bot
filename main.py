import os
import logging
import threading
import requests
import json
import time
from http.server import HTTPServer, BaseHTTPRequestHandler
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
HF_TOKEN = os.environ.get("HF_TOKEN")

# --- Ø¢Ø¯Ø±Ø³ Ù¾Ø§ÛŒÙ‡ Hugging Face Inference API ---
# Ø§ÛŒÙ† Ø¢Ø¯Ø±Ø³ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ø³Øª Ùˆ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ø± Ú©Ù†Ø¯
HF_INFERENCE_API_BASE_URL = "https://api-inference.huggingface.co/models/"
# ---------------------------------------------

# --- Ø³Ø±ÙˆØ± Ø§Ù„Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨ÛŒØ¯Ø§Ø± Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Render ---
class SimpleHTTPRequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"Bot is alive and well! (Serving dummy page)")

def run_fake_server():
    port = int(os.environ.get("PORT", 8080))
    server = HTTPServer(('0.0.0.0', port), SimpleHTTPRequestHandler)
    print(f"ğŸŒ Fake server running on port {port}")
    server.serve_forever()

threading.Thread(target=run_fake_server, daemon=True).start()
# ---------------------------------------------

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ù…Ø¯Ù„ Text Generation
def get_working_hf_model(hf_token):
    if not hf_token:
        logger.error("HF_TOKEN is not set, cannot query Hugging Face models.")
        return None, "Error: HF_TOKEN is missing."

    # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Text Generation Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ ÙØ¹Ø§Ù„ Ù‡Ø³ØªÙ†Ø¯
    common_text_gen_models = [
        "gpt2",
        "distilgpt2",
        "facebook/opt-125m",
        "EleutherAI/gpt-neo-125m",
        "databricks/dolly-v2-3b", # Ø§ÛŒÙ† Ú©Ù…ÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø§Ø³Øª
    ]

    headers = {"Authorization": f"Bearer {hf_token}"}

    for model_name in common_text_gen_models:
        test_url = f"{HF_INFERENCE_API_BASE_URL}{model_name}"
        try:
            # ÛŒÚ© Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø¯Ù„
            test_response = requests.post(
                test_url,
                headers=headers,
                json={"inputs": "test input", "parameters": {"max_new_tokens": 1}}
            )
            if test_response.status_code == 200:
                logger.info(f"âœ… Found working Hugging Face model: {model_name}")
                return model_name, None
            elif test_response.status_code == 503:
                logger.info(f"Model {model_name} is loading (Cold Boot)...")
                # Ø§Ú¯Ù‡ Cold Boot Ø¨ÙˆØ¯ØŒ Ø±Ø¯ Ø´ÙˆØŒ Ø´Ø§ÛŒØ¯ Ù…Ø¯Ù„ Ø¨Ø¹Ø¯ÛŒ Ø¨ÛŒØ¯Ø§Ø± Ø¨Ø§Ø´Ù‡
                continue
            else:
                logger.warning(f"Model {model_name} returned {test_response.status_code}: {test_response.text}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"Failed to connect to model {model_name}: {e}")
            continue # Ø§Ú¯Ù‡ Ø§ÛŒÙ† Ù…Ø¯Ù„ ÙˆØµÙ„ Ù†Ø´Ø¯ØŒ Ø¨Ø¹Ø¯ÛŒ Ø±Ùˆ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†
    
    logger.error("âŒ No working Hugging Face Text Generation model found among common ones.")
    return None, "Error: No active Hugging Face model found for text generation."

# Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ù…ÙˆÙ‚Ø¹ Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª
HF_MODEL_ID, HF_MODEL_ERROR = get_working_hf_model(HF_TOKEN)


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if HF_MODEL_ID:
        await update.message.reply_text(f"Ø³Ù„Ø§Ù…! Ø±Ø¨Ø§Øª Ø¨Ø§ Ù…Ø¯Ù„ {HF_MODEL_ID} (Hugging Face) Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Øª. ÛŒÙ‡ Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ú¯Ùˆ! ğŸš€")
    else:
        await update.message.reply_text(f"âŒ Ø±Ø¨Ø§Øª Ù†ØªÙˆØ§Ù†Ø³Øª Ø¨Ù‡ Ù…Ø¯Ù„ Hugging Face ÙˆØµÙ„ Ø´ÙˆØ¯: {HF_MODEL_ERROR}")


async def generate_content(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not HF_MODEL_ID:
        await update.message.reply_text(f"âŒ Ø±Ø¨Ø§Øª Ù†ØªÙˆØ§Ù†Ø³Øª Ø¨Ù‡ Ù…Ø¯Ù„ Hugging Face ÙˆØµÙ„ Ø´ÙˆØ¯: {HF_MODEL_ERROR}")
        return

    user_text = update.message.text
    wait_msg = await update.message.reply_text("â³ Ø¯Ø§Ø±Ù… Ø§Ø² Hugging Face Ù…ÛŒâ€ŒÙ¾Ø±Ø³Ù… (Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØ§ Û³Û° Ø«Ø§Ù†ÛŒÙ‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯)...")

    try:
        # Ù¾Ø±Ø§Ù…Ù¾Øª
        prompt = f"Instagram content ideas for '{user_text}' in Persian (Farsi):\n"
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡
        API_URL = f"{HF_INFERENCE_API_BASE_URL}{HF_MODEL_ID}"
        headers = {"Authorization": f"Bearer {HF_TOKEN}"}

        response = requests.post(
            API_URL, 
            headers=headers, 
            json={"inputs": prompt, "parameters": {"max_new_tokens": 200}},
            timeout=90 # 90 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® ØµØ¨Ø± Ù…ÛŒÚ©Ù†ÛŒÙ…
        )
            
        if response.status_code == 200:
            try:
                result = response.json()
                if isinstance(result, list) and len(result) > 0 and 'generated_text' in result[0]:
                    final_text = result[0]['generated_text'].replace(prompt, "").strip()
                    if final_text:
                        await context.bot.delete_message(chat_id=update.effective_chat.id, message_id=wait_msg.message_id)
                        await update.message.reply_text(f"**Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ {user_text}:**\n{final_text}")
                        return # Ù…ÙˆÙÙ‚ÛŒØª!
                    else:
                        raise Exception("Generated text is empty.")
                else:
                    raise Exception(f"Invalid JSON structure. Response: {json.dumps(result)}")
            except json.JSONDecodeError:
                raw_response_text = response.text
                raise Exception(f"Hugging Face returned non-JSON data. Raw: {raw_response_text[:500]}...")
        elif response.status_code == 503: # Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ Cold Boot Ø§Ø³Øª
            await context.bot.edit_message_text(
                chat_id=update.effective_chat.id,
                message_id=wait_msg.message_id,
                text="âš ï¸ Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ Ø¨ÛŒØ¯Ø§Ø± Ø´Ø¯Ù† Ø§Ø³Øª (Cold Boot). Ù„Ø·ÙØ§Ù‹ Û³Û° Ø«Ø§Ù†ÛŒÙ‡ Ø¯ÛŒÚ¯Ø± Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯."
            )
        else:
            raise Exception(f"Hugging Face API Error: {response.status_code} - {response.text}")
        
    except requests.exceptions.Timeout:
        logger.error("Request to Hugging Face timed out.")
        await context.bot.edit_message_text(
            chat_id=update.effective_chat.id, 
            message_id=wait_msg.message_id, 
            text="âŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø³Ø±ÙˆØ± Ø´Ù„ÙˆØº Ø¨Ø§Ø´Ø¯. Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯."
        )
    except Exception as e:
        logger.error(f"General Error: {e}")
        await context.bot.edit_message_text(
            chat_id=update.effective_chat.id, 
            message_id=wait_msg.message_id, 
            text=f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ: {e}"
        )

if __name__ == '__main__':
    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    application.add_handler(CommandHandler('start', start))
    application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), generate_content))
    print("ğŸ¤– BOT STARTED WITH HUGGING FACE (Dynamic Model Selection)...")
    application.run_polling()
        
